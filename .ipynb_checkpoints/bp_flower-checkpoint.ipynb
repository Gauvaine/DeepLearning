{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fbbad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy import *\n",
    "from functools import reduce\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "055ad105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inX):\n",
    "    return 1.0 / (1 + exp(-inX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d979406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,layer_index,node_index):\n",
    "        self.layer_index=layer_index\n",
    "        self.node_index=node_index\n",
    "        self.downstream=[]\n",
    "        self.upstream=[]\n",
    "        self.output=0\n",
    "        self.delta=0\n",
    "    \n",
    "    #设置节点的输出值，如果节点属于输入层会用到这个函数\n",
    "    def set_output(self,output):\n",
    "        self.output=output \n",
    "    \n",
    "    #添加一个到下游节点的连接\n",
    "    def append_downstream_connection(self,conn):\n",
    "        self.downstream.append(conn)\n",
    "        \n",
    "    #添加一个到上游节点的连接\n",
    "    def append_upstream_connection(self,conn):\n",
    "        self.upstream.append(conn)\n",
    "        \n",
    "    #计算节点的输出\n",
    "    def calc_output(self):\n",
    "        output=reduce(lambda ret,conn:ret+conn.upstream_node.output*conn.weight,self.upstream,0)\n",
    "        self.output=sigmoid(output)\n",
    "        \n",
    "    #计算隐藏层delta\n",
    "    def calc_hidden_layer_delta(self):\n",
    "        downstream_delta=reduce(lambda ret,conn:ret+conn.downstream_node.delta*conn.weight,self.downstream,0.0)\n",
    "        self.delta=self.output*(1-self.output)*downstream_delta\n",
    "        \n",
    "    #计算输出层delta\n",
    "    def calc_output_layer_delta(self,label):\n",
    "        self.delta=self.output*(1-self.output)*(label-self.output)\n",
    "        \n",
    "    #打印节点信息\n",
    "    def __str__(self):\n",
    "        node_str = '%u-%u: output: %f delta: %f' % (self.layer_index, self.node_index, self.output, self.delta)\n",
    "        downstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.downstream, '')\n",
    "        upstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.upstream, '')\n",
    "        return node_str + '\\n\\tdownstream:' + downstream_str + '\\n\\tupstream:' + upstream_str \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30abb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现一个输出恒为1的节点（计算偏置项Wb时需要）\n",
    "class ConstNode(object):\n",
    "    def __init__(self,layer_index,node_index):\n",
    "        self.layer_index=layer_index\n",
    "        self.node_index=node_index\n",
    "        self.downstream=[]\n",
    "        self.output=1\n",
    "    \n",
    "    #添加一个到下游节点的连接\n",
    "    def append_downstream_connection(self,conn):\n",
    "        self.downstream.append(conn)\n",
    "        \n",
    "    #计算隐藏层delta\n",
    "    def calc_hidden_layer_delta(self):\n",
    "        downstream_delta=reduce(lambda ret,conn:ret+conn.downstream_node.delta*conn.weight,self.downstream,0.0)\n",
    "        self.delta=self.output*(1-self.output)*downstream_delta\n",
    "        \n",
    "    #打印节点信息\n",
    "    def __str__(self):\n",
    "        node_str = '%u-%u: output: 1' % (self.layer_index, self.node_index)\n",
    "        downstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.downstream, '')\n",
    "        return node_str + '\\n\\tdownstream:' + downstream_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ff151d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer对象，负责初始化一层。此外，作为Node的集合对象，提供对Node集合的操作\n",
    "class Layer(object):\n",
    "    def __init__(self,layer_index,node_count):\n",
    "        self.layer_index=layer_index\n",
    "        self.nodes=[]\n",
    "        for i in range(node_count):\n",
    "            self.nodes.append(Node(layer_index,i))\n",
    "        self.nodes.append(ConstNode(layer_index,node_count))\n",
    "        \n",
    "    #设置层的输出值，如果层是输入层会用到这个函数\n",
    "    def set_output(self,data):\n",
    "        for i in range(len(data)):\n",
    "            self.nodes[i].set_output(data[i])\n",
    "            \n",
    "    #计算层的输出向量\n",
    "    def calc_output(self):\n",
    "        for node in self.nodes[:-1]:#不包括最后一个节点,即ConstNode\n",
    "            node.calc_output()\n",
    "            \n",
    "    #打印层的信息\n",
    "    def dump(self):\n",
    "        for node in self.nodes:\n",
    "            print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf964d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection对象，主要记录连接的权重，以及该连接所关联的上下游节点\n",
    "class Connection(object):\n",
    "    def __init__(self,upstream_node,downstream_node):\n",
    "        self.upstream_node=upstream_node\n",
    "        self.downstream_node=downstream_node\n",
    "        self.weight=random.uniform(-0.1,0.1)\n",
    "        self.gradient=0.0\n",
    "        \n",
    "    def calc_gradient(self):\n",
    "        self.gradient=self.downstream_node.delta*self.upstream_node.output\n",
    "        \n",
    "    def get_gradient(self):\n",
    "        return self.gradient\n",
    "    \n",
    "    def update_weight(self,rate):\n",
    "        self.calc_gradient()\n",
    "        self.weight+=rate*self.gradient\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '(%u-%u) -> (%u-%u) = %f' % (\n",
    "            self.upstream_node.layer_index, \n",
    "            self.upstream_node.node_index,\n",
    "            self.downstream_node.layer_index, \n",
    "            self.downstream_node.node_index, \n",
    "            self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "789ada5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connections对象，提供Connection集合操作\n",
    "class Connections(object):\n",
    "    def __init__(self):\n",
    "        self.connections=[]\n",
    "    \n",
    "    def add_connection(self,connection):\n",
    "        self.connections.append(connection)\n",
    "        \n",
    "    def dump(self):\n",
    "        for conn in self.connections:\n",
    "            print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e532c2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 15 (2153567086.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[46], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.connections.add_connection(conn)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 15\n"
     ]
    }
   ],
   "source": [
    "#Network对象，提供API\n",
    "class Network(object):\n",
    "    #初始化一个全连接神经网络，layers：二维数组，描述神经网络每层节点数\n",
    "    def __init__(self,layers):\n",
    "        self.connections=Connections()\n",
    "        self.layers=[]\n",
    "        layer_count=len(layers)\n",
    "        node_count=0\n",
    "        for i in range(layer_count):\n",
    "            self.layers.append(Layer(i,layers[i]))\n",
    "        for layer in range(layer_count-1):\n",
    "            connections=[Connection(upstream_node,downstream_node)\n",
    "                        for upstream_node in self.layers[layer].nodes\n",
    "                        for downstream_node in self.layers[layer+1].nodes[:-1]]\n",
    "            for conn in connections:\n",
    "                self.connections.add_connection(conn)\n",
    "                conn.downstream_node.append_upstream_connection(conn)\n",
    "                conn.upstream_node.append_downstream_connection(conn)\n",
    "    \n",
    "    #训练神经网络\n",
    "    def train(self,labels,data_set,rate,iteration):\n",
    "        for i in range(iteration):\n",
    "            for d in range(len(data_set)):\n",
    "                self.train_one_sample(labels[d],data_set[d],rate)\n",
    "                # print 'sample %d training finished' % d\n",
    "    \n",
    "    #用一个样本训练网络\n",
    "    def train_one_sample(self,label,sample,rate):\n",
    "        self.predict(sample)\n",
    "        self.calc_delta(label)\n",
    "        self.update_weight(rate)\n",
    "    \n",
    "    #计算每个节点的delta\n",
    "    #self.layers[-2::-1]是Python中一种切片操作，用于获取列表或其他可迭代对象的子序列。\n",
    "    #-2表示从倒数第二个元素开始。在这里，它指的是self.layers列表中倒数第二个元素，即倒数第二层的节点列表。\n",
    "    #::-1表示反向迭代，即从倒数第二个元素开始逆序向前遍历。这样做的目的是从倒数第二层开始，依次向前遍历神经网络的隐藏层。\n",
    "    #因此，self.layers[-2::-1]返回了从倒数第二层开始到第一层（不包括第一层）的所有隐藏层的节点列表。\n",
    "    def calc_delta(self,label):\n",
    "        output_nodes=self.layers[-1].nodes\n",
    "        for i in range(len(label)):\n",
    "            output_nodes[i].calc_output_layer_delta(label[i])\n",
    "        for layer in self.layers[-2::-1]:\n",
    "            for node in layer.nodes:\n",
    "                node.calc_hidden_layer_delta()\n",
    "                \n",
    "    #更新每个连接的权重\n",
    "    def update_weight(self,rate):\n",
    "        for layer in self.layers[:-1]:\n",
    "            for node in layer.nodes:\n",
    "                for conn in node.downstream:\n",
    "                    conn.update_weight(rate)\n",
    "                \n",
    "    #计算每个连接的梯度\n",
    "    def calc_gradient(self):\n",
    "        for layer in self.layers[:-1]:\n",
    "            for node in layer.nodes:\n",
    "                for conn in node.downstream:\n",
    "                    conn.calc_gradient()\n",
    "                    \n",
    "    #获得网络在一个样本下，每个连接上的梯度\n",
    "    def get_gradient(self,label,sample):\n",
    "        self.predict(sample)\n",
    "        self.calc_delta(label)\n",
    "        self.calc_gradient()\n",
    "        \n",
    "    #根据输入的样本预测输出值\n",
    "    def predict(self,sample):\n",
    "        self.layers[0].set_output(sample)\n",
    "        for i in range(1,len(self.layers)):\n",
    "            self.layers[i].calc_output()\n",
    "        return list(map(lambda node:node.output,self.layers[-1].nodes[:-1]))\n",
    "        #获取这一层的节点时去掉最后一个节点。不过，最后一个节点通常是用于偏置项的\n",
    "    \n",
    "    #打印网络信息\n",
    "    def dump(self):\n",
    "        for layer in self.layers:\n",
    "            layer.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6263b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(network, sample_feature, sample_label):\n",
    "    '''\n",
    "    梯度检查\n",
    "    network: 神经网络对象\n",
    "    sample_feature: 样本的特征\n",
    "    sample_label: 样本的标签\n",
    "    '''\n",
    "    # 计算网络误差\n",
    "    network_error = lambda vec1, vec2: \\\n",
    "            0.5 * reduce(lambda a, b: a + b, \n",
    "                      list(map(lambda v: (v[0] - v[1]) * (v[0] - v[1]),\n",
    "                          zip(vec1, vec2))))\n",
    "\n",
    "    # 获取网络在当前样本下每个连接的梯度\n",
    "    network.get_gradient(sample_feature, sample_label)\n",
    "\n",
    "    # 对每个权重做梯度检查    \n",
    "    for conn in network.connections.connections: \n",
    "        # 获取指定连接的梯度\n",
    "        actual_gradient = conn.get_gradient()\n",
    "    \n",
    "        # 增加一个很小的值，计算网络的误差\n",
    "        epsilon = 0.0001\n",
    "        conn.weight += epsilon\n",
    "        error1 = network_error(network.predict(sample_feature), sample_label)\n",
    "    \n",
    "        # 减去一个很小的值，计算网络的误差\n",
    "        conn.weight -= 2 * epsilon # 刚才加过了一次，因此这里需要减去2倍\n",
    "        error2 = network_error(network.predict(sample_feature), sample_label)\n",
    "    \n",
    "        # 根据式6计算期望的梯度值\n",
    "        expected_gradient = (error2 - error1) / (2 * epsilon)\n",
    "    \n",
    "        # 打印\n",
    "        print('expected gradient: \\t%f\\nactual gradient: \\t%f' % (\n",
    "            expected_gradient, actual_gradient))\n",
    "\n",
    "def gradient_check_test():\n",
    "    net = Network([2, 2, 2])\n",
    "    sample_feature = [0.9, 0.1]\n",
    "    sample_label = [0.9, 0.1]\n",
    "    gradient_check(net, sample_feature, sample_label)        \n",
    "        \n",
    "''''\n",
    "首先，代码创建了一个 Normalizer 的实例，这很可能是一个用于对数据进行归一化处理的类的实例。\n",
    "然后，代码初始化了两个空列表 data_set 和 labels，用于存储训练数据和相应的标签。\n",
    "最后，函数返回了生成的标签列表和数据集列表。\n",
    "'''\n",
    "def train_data_set():\n",
    "    data = pd.read_csv('data/iris/iris.data', header=None)\n",
    "    x, y = data[[0, 1, 2, 3]], pd.Categorical(data[4]).codes\n",
    "    data_set = x.values.tolist()\n",
    "    labels = _convert_label(y.tolist())\n",
    "    # print(type(labels), labels)\n",
    "    # print(data_set)\n",
    "    return labels, data_set\n",
    "\n",
    "\n",
    "# 把鸢尾花分类转化成ond-hot的三维数组\n",
    "def _convert_label(lables):\n",
    "    new_list = []\n",
    "    for item in lables:\n",
    "        if item == 0:\n",
    "            new_list.append([0.9, 0.1, 0.1])\n",
    "        elif item == 1:\n",
    "            new_list.append([0.1, 0.9, 0.1])\n",
    "        elif item == 2:\n",
    "            new_list.append([0.1, 0.1, 0.9])\n",
    "    return new_list\n",
    "\n",
    "\n",
    "def train(network):\n",
    "    # 断言语句，用来确保network是一个对象的实例。如果不是，则会引发AssertionError异常\n",
    "    assert isinstance(network, object)\n",
    "    labels, data_set = train_data_set()\n",
    "    network.train(labels, data_set, 0.3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c2a70c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0: output: 5.900000 delta: -0.000000\n",
      "\tdownstream:\n",
      "\tupstream:\n",
      "0-1: output: 3.000000 delta: -0.000000\n",
      "\tdownstream:\n",
      "\tupstream:\n",
      "0-2: output: 5.100000 delta: -0.000000\n",
      "\tdownstream:\n",
      "\tupstream:\n",
      "0-3: output: 1.800000 delta: -0.000000\n",
      "\tdownstream:\n",
      "\tupstream:\n",
      "0-4: output: 1\n",
      "\tdownstream:\n",
      "1-0: output: 0.500000 delta: 0.008565\n",
      "\tdownstream:\n",
      "\t(1-0) -> (2-0) = -0.582422\n",
      "\t(1-0) -> (2-1) = -0.371922\n",
      "\t(1-0) -> (2-2) = 0.278147\n",
      "\tupstream:\n",
      "1-1: output: 0.500000 delta: 0.006848\n",
      "\tdownstream:\n",
      "\t(1-1) -> (2-0) = -0.508487\n",
      "\t(1-1) -> (2-1) = -0.384890\n",
      "\t(1-1) -> (2-2) = 0.153316\n",
      "\tupstream:\n",
      "1-2: output: 1\n",
      "\tdownstream:\n",
      "\t(1-2) -> (2-0) = -0.921614\n",
      "\t(1-2) -> (2-1) = -0.609817\n",
      "\t(1-2) -> (2-2) = 0.518770\n",
      "2-0: output: 0.188315 delta: -0.013499\n",
      "\tdownstream:\n",
      "\tupstream:\n",
      "\t(1-0) -> (2-0) = -0.582422\n",
      "\t(1-1) -> (2-0) = -0.508487\n",
      "\t(1-2) -> (2-0) = -0.921614\n",
      "2-1: output: 0.274362 delta: -0.034713\n",
      "\tdownstream:\n",
      "\tupstream:\n",
      "\t(1-0) -> (2-1) = -0.371922\n",
      "\t(1-1) -> (2-1) = -0.384890\n",
      "\t(1-2) -> (2-1) = -0.609817\n",
      "2-2: output: 0.670782 delta: 0.050619\n",
      "\tdownstream:\n",
      "\tupstream:\n",
      "\t(1-0) -> (2-2) = 0.278147\n",
      "\t(1-1) -> (2-2) = 0.153316\n",
      "\t(1-2) -> (2-2) = 0.518770\n",
      "2-3: output: 1\n",
      "\tdownstream:\n",
      "[0.18738852947150275, 0.2712631769576377, 0.6757921468852992]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # gradient_check_test()\n",
    "    # 设置神经网络初始化参数，初始化神经网络,列表长度表示网络层数，每个数字表示每一层节点个数\n",
    "    test_samples = [5.4, 3.4, 1.7, 0.2]\n",
    "    net = Network([4, 2, 3])\n",
    "    train(net)\n",
    "    # net.dump()\n",
    "    print(net.predict(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4aff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
