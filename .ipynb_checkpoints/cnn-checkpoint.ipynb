{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9929b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%run activators.ipynb\n",
    "# from activators import ReluActivator, IdentityActivator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fcb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得卷积区域\n",
    "def get_patch(input_array,i,j,filter_width,filter_height,stride):\n",
    "    '''\n",
    "    从输入数组中获取本次卷积的区域，\n",
    "    自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    start_i=i*stride\n",
    "    start_j=j*stride\n",
    "    if input_array.ndim==2:\n",
    "        return input_array[\n",
    "            start_i:start_i+filter_height,\n",
    "            start_j:start_j+filter_width]\n",
    "    elif input_array.ndim==3:\n",
    "        return input_array[:,\n",
    "                start_i:start_i+filter_height,\n",
    "                start_j:start_j+filter_width]\n",
    "    \n",
    "# 获取一个2D区域的最大值所在的索引\n",
    "def get_max_index(array):\n",
    "    max_i=0\n",
    "    max_j=0\n",
    "    max_value=array[0,0]\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            if array[i,j]>max_value:\n",
    "                max_value=array[i,j]\n",
    "                max_i,max_j=i,j\n",
    "    return max_i,max_j\n",
    "\n",
    "# 计算卷积\n",
    "def conv(input_array,kernel_array,output_array,stride,bias):\n",
    "    '''\n",
    "    计算卷积，自动适配输入为2D和3D的情况\n",
    "    depth:0,height:1(-2),width:2(-1)\n",
    "    '''\n",
    "    channel_number=input_array.ndim\n",
    "    output_width=output_array.shape[1]\n",
    "    output_height=output_array.shape[0]\n",
    "    kernel_width=kernel_array.shape[-1]\n",
    "    kernel_height=kernel_array.shape[-2]\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            output_array[i][j]=(\n",
    "                get_patch(input_array,i,j,kernel_width,kernel_height,stride)*kernel_array).sum()+bias\n",
    "    \n",
    "# 为数组增加Zero padding\n",
    "def padding(input_array,zp):\n",
    "    '''\n",
    "    为数组增加Zero padding，自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    if zp==0:\n",
    "        return input_array\n",
    "    else:\n",
    "        if input_array.ndim==3:\n",
    "            input_width = input_array.shape[2]\n",
    "            input_height = input_array.shape[1]\n",
    "            input_depth = input_array.shape[0]\n",
    "            padded_array=np.zeros((input_depth,\n",
    "                                input_height+2*zp,\n",
    "                                input_width+2*zp))\n",
    "            padded_array[:,\n",
    "                         zp:zp+input_height,\n",
    "                         zp:zp+input_width]=input_array\n",
    "            return padded_array\n",
    "        elif input_array.ndim==2:\n",
    "            input_width = input_array.shape[1]\n",
    "            input_height = input_array.shape[0]\n",
    "            padded_array=np.zeros((input_height+2*zp,\n",
    "                                  input_width+2*zp))\n",
    "            padded_array[zp:zp+input_height,\n",
    "                         zp:zp+input_width]=input_array\n",
    "            return padded_array\n",
    "        \n",
    "# 对numpy数组进行element wise操作\n",
    "def element_wise_op(array, op):\n",
    "    # np.nditer是迭代器，array[...]即array[:,:,:]\n",
    "    for i in np.nditer(array,\n",
    "                       op_flags=['readwrite']):\n",
    "        i[...] = op(i)\n",
    "        \n",
    "# 保存卷积层的参数以及梯度，并且实现了用梯度下降算法来更新参数\n",
    "class Filter(object):\n",
    "    def __init__(self,width,height,depth):\n",
    "        self.weights=np.random.uniform(-1e-4,1e-4,(depth,height,width))\n",
    "        self.bias=0\n",
    "        self.weights_grad=np.zeros(self.weights.shape)\n",
    "        self.bias_grad=0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'filter weights:\\n%s\\nbias:\\n%s' % (\n",
    "            repr(self.weights), repr(self.bias))\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def get_bias(self):\n",
    "        return self.bias\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.weights_grad\n",
    "        self.bias -= learning_rate * self.bias_grad\n",
    "\n",
    "# 初始化卷积层，并可在构造函数中设置卷基层的超参数\n",
    "class ConvLayer(object):\n",
    "    def __init__(self,input_width,input_height,channel_number,\n",
    "                     filter_width,filter_height,filter_number,\n",
    "                     zero_padding,stride,activator,learning_rate):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.channel_number = channel_number\n",
    "        \n",
    "        self.filter_width = filter_width\n",
    "        self.filter_height = filter_height\n",
    "        self.filter_number = filter_number\n",
    "        \n",
    "        self.zero_padding = zero_padding\n",
    "        self.stride = stride\n",
    "        self.activator = activator\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.output_width = ConvLayer.calculate_output_size(\n",
    "            self.input_width, filter_width, zero_padding,stride)\n",
    "        self.output_height = ConvLayer.calculate_output_size(\n",
    "            self.input_height, filter_height, zero_padding,stride)\n",
    "        self.output_array = np.zeros((self.filter_number, self.output_height, self.output_width))\n",
    "        \n",
    "        self.filters = []\n",
    "        for i in range(filter_number):\n",
    "            self.filters.append(Filter(filter_width, filter_height, self.channel_number))\n",
    "        \n",
    "    def forward(self,input_array):\n",
    "        '''\n",
    "        计算卷积层的输出\n",
    "        输出结果保存在self.output_array\n",
    "        '''\n",
    "        self.input_array=input_array\n",
    "        self.padded_input_array=padding(input_array,self.zero_padding)\n",
    "        for f in range(self.filter_number):\n",
    "            filter=self.filters[f]\n",
    "            conv(self.padded_input_array,filter.get_weights(),self.output_array[f],self.stride,filter.get_bias())\n",
    "        element_wise_op(self.output_array,self.activator.forward)\n",
    "            \n",
    "    def backward(self,input_array,sensitivity_array,activator):\n",
    "        '''\n",
    "        计算传递给前一层的误差项，以及计算每个权重的梯度\n",
    "        前一层的误差项保存在self.delta_array\n",
    "        梯度保存在Filter对象的weights_grad\n",
    "        '''\n",
    "        self.forward(input_array)\n",
    "        self.bp_sensitivity_map(sensitivity_array,activator)\n",
    "        self.bp_gradient(sensitivity_array)\n",
    "            \n",
    "    def bp_sensitivity_map(self,sensitivity_array,activator):\n",
    "        '''\n",
    "        计算传递到上一层的sensitivity map\n",
    "        sensitivity_array: 本层的sensitivity map\n",
    "        activator: 上一层的激活函数\n",
    "        '''\n",
    "        # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(sensitivity_array)\n",
    "        # full卷积，对sensitivitiy map进行zero padding\n",
    "        # 虽然原始输入的zero padding单元也会获得残差\n",
    "        # 但这个残差不需要继续向上传递，因此就不计算了\n",
    "        expanded_width = expanded_array.shape[2]\n",
    "        zp = (self.input_width +  self.filter_width - 1 - expanded_width) / 2\n",
    "        padded_array = padding(expanded_array, zp)\n",
    "        # 初始化delta_array，用于保存传递到上一层的sensitivity map\n",
    "        self.delta_array = self.create_delta_array()\n",
    "        # 对于具有多个filter的卷积层来说，最终传递到上一层的sensitivity map相当于所有的filter的sensitivity map之和\n",
    "        for f in range(self.filter_number):\n",
    "            filter=self.filters[f]\n",
    "            # 将filter权重翻转180度\n",
    "            flipped_weights = np.array(map(lambda i: np.rot90(i, 2), filter.get_weights()))\n",
    "            # 计算与一个filter对应的delta_array\n",
    "            delta_array = self.create_delta_array()\n",
    "            for d in range(delta_array.shape[0]):\n",
    "                conv(padded_array[f], flipped_weights[d],delta_array[d], 1, 0)\n",
    "            self.delta_array += delta_array\n",
    "        # 将计算结果与激活函数的偏导数做element-wise乘法操作,derivative_array即为偏导数数组\n",
    "        derivative_array = np.array(self.input_array)\n",
    "        element_wise_op(derivative_array, activator.backward)\n",
    "        self.delta_array *= derivative_array\n",
    "            \n",
    "    def expand_sensitivity_map(self, sensitivity_array):\n",
    "        depth = sensitivity_array.shape[0]\n",
    "        # 确定扩展后sensitivity map的大小\n",
    "        # 计算stride为1时sensitivity map的大小\n",
    "        expanded_width = (self.input_width - self.filter_width + 2 * self.zero_padding + 1)\n",
    "        expanded_height = (self.input_height - self.filter_height + 2 * self.zero_padding + 1)\n",
    "        # 构建新的sensitivity_map\n",
    "        expand_array = np.zeros((depth, expanded_height, expanded_width))\n",
    "        # 从原始sensitivity map拷贝误差值\n",
    "        for i in range(self.output_height):\n",
    "            for j in range(self.output_width):\n",
    "                i_pos = i * self.stride\n",
    "                j_pos = j * self.stride\n",
    "                expand_array[:,i_pos,j_pos] = sensitivity_array[:,i,j]\n",
    "        return expand_array\n",
    " \n",
    "            \n",
    "    def create_delta_array(self):\n",
    "        return np.zeros((self.channel_number,self.input_height, self.input_width))\n",
    "        \n",
    "    def bp_gradient(self, sensitivity_array):\n",
    "    # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(sensitivity_array)\n",
    "        for f in range(self.filter_number):\n",
    "            # 计算每个权重的梯度\n",
    "            filter = self.filters[f]\n",
    "            for d in range(filter.weights.shape[0]):\n",
    "                conv(self.padded_input_array[d], expanded_array[f],filter.weights_grad[d], 1, 0)\n",
    "        # 计算偏置项的梯度\n",
    "        filter.bias_grad = expanded_array[f].sum()\n",
    "            \n",
    "    def update(self):\n",
    "        '''\n",
    "        按照梯度下降，更新权重\n",
    "        '''\n",
    "        for filter in self.filters:\n",
    "            filter.update(self.learning_rate)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_output_size(input_size,filter_size, zero_padding, stride):\n",
    "        return (input_size - filter_size + 2 * zero_padding) / stride + 1\n",
    "        \n",
    "class MaxPoolingLayer(object):\n",
    "    def __init__(self,input_width,input_height,channel_number,filter_width,filter_height,stride):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.channel_number = channel_number\n",
    "        self.filter_width = filter_width\n",
    "        self.filter_height = filter_height\n",
    "        self.stride = stride\n",
    "        self.output_width = (input_width - filter_width) / self.stride + 1\n",
    "        self.output_height = (input_height - filter_height) / self.stride + 1\n",
    "        self.output_array = np.zeros((self.channel_number,self.output_height, self.output_width))\n",
    "    \n",
    "    def forward(self,input_array):\n",
    "        for d in range(self.channel_number):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    self.output_array[d,i,j]=(get_patch(input_array[d],i,j,self.filter_width,self.filter_height,self.stride).max())\n",
    "    \n",
    "    def backward(self,input_array,sensitivity_array):\n",
    "        self.delta_array=np.zeros(input_array.shape)\n",
    "        for d in range(self.channel_number):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    patch_array=get_patch(input_array[d],i,j,self.filter_width,self.filter_height,self.stride)\n",
    "                    k,l=get_max_index(patch_array)\n",
    "                    self.delta_array[d,i*self.stride+k,j*self.stride+l]=sensitivity_array[d,i,j]\n",
    "                    \n",
    "def init_test():\n",
    "    a=np.array( \n",
    "        [[[0,1,1,0,2],\n",
    "          [2,2,2,2,1],\n",
    "          [1,0,0,2,0],\n",
    "          [0,1,1,0,0],\n",
    "          [1,2,0,0,2]],\n",
    "         [[1,0,2,2,0],\n",
    "          [0,0,0,2,0],\n",
    "          [1,2,1,2,1],\n",
    "          [1,0,0,0,0],\n",
    "          [1,2,1,1,1]],\n",
    "         [[2,1,2,0,0],\n",
    "          [1,0,0,1,0],\n",
    "          [0,2,1,0,1],\n",
    "          [0,1,2,2,2],\n",
    "          [2,1,0,0,1]]])\n",
    "    b = np.array(\n",
    "        [[[0,1,1],\n",
    "          [2,2,2],\n",
    "          [1,0,0]],\n",
    "         [[1,0,2],\n",
    "          [0,0,0],\n",
    "          [1,2,1]]])\n",
    "    cl = ConvLayer(5,5,3,3,3,2,1,2,IdentityActivator(),0.001)\n",
    "    cl.filters[0].weights = np.array(\n",
    "        [[[-1,1,0],\n",
    "          [0,1,0],\n",
    "          [0,1,1]],\n",
    "         [[-1,-1,0],\n",
    "          [0,0,0],\n",
    "          [0,-1,0]],\n",
    "         [[0,0,-1],\n",
    "          [0,1,0],\n",
    "          [1,-1,-1]]], dtype=np.float64)\n",
    "    cl.filters[0].bias=1\n",
    "    cl.filters[1].weights = np.array(\n",
    "        [[[1,1,-1],\n",
    "          [-1,-1,1],\n",
    "          [0,-1,1]],\n",
    "         [[0,1,0],\n",
    "         [-1,0,-1],\n",
    "          [-1,1,0]],\n",
    "         [[-1,0,0],\n",
    "          [-1,0,1],\n",
    "          [-1,0,0]]], dtype=np.float64)\n",
    "    return a, b, cl\n",
    "\n",
    "def test():\n",
    "    a,b,cl=init_test()\n",
    "    cl.forward(a)\n",
    "    print(cl.output_array)\n",
    "    \n",
    "def test_bp():\n",
    "    a,b,cl=init_test()\n",
    "    cl.backward(a,b,IdentityActivator())\n",
    "    cl.update()\n",
    "    print(cl.filters[0])\n",
    "    print(cl.filters[1])\n",
    "    \n",
    "def gradient_check():\n",
    "    '''\n",
    "    梯度检查\n",
    "    '''\n",
    "    # 设计一个误差函数，取所有节点输出项之和\n",
    "    error_function = lambda o: o.sum()\n",
    "    \n",
    "    # 计算forward值\n",
    "    a, b, cl = init_test()\n",
    "    cl.forward(a)\n",
    "    \n",
    "    # 求取sensitivity map\n",
    "    sensitivity_array = np.ones(cl.output_array.shape,dtype=np.float64)\n",
    "    # 计算梯度\n",
    "    cl.backward(a, sensitivity_array,IdentityActivator())\n",
    "    # 检查梯度\n",
    "    epsilon = 10e-4\n",
    "    for d in range(cl.filters[0].weights_grad.shape[0]):\n",
    "        for i in range(cl.filters[0].weights_grad.shape[1]):\n",
    "            for j in range(cl.filters[0].weights_grad.shape[2]):\n",
    "                cl.filters[0].weights[d,i,j] += epsilon\n",
    "                cl.forward(a)\n",
    "                err1 = error_function(cl.output_array)\n",
    "                cl.filters[0].weights[d,i,j] -= 2*epsilon\n",
    "                cl.forward(a)\n",
    "                err2 = error_function(cl.output_array)\n",
    "                expect_grad = (err1 - err2) / (2 * epsilon)\n",
    "                cl.filters[0].weights[d,i,j] += epsilon\n",
    "                print('weights(%d,%d,%d): expected - actural %f - %f' % (d, i, j, expect_grad, cl.filters[0].weights_grad[d,i,j]))\n",
    "    \n",
    "def init_pool_test():\n",
    "    a = np.array(\n",
    "        [[[1,1,2,4],\n",
    "          [5,6,7,8],\n",
    "          [3,2,1,0],\n",
    "          [1,2,3,4]],\n",
    "         [[0,1,2,3],\n",
    "          [4,5,6,7],\n",
    "          [8,9,0,1],\n",
    "          [3,4,5,6]]], dtype=np.float64)\n",
    "    b = np.array(\n",
    "        [[[1,2],\n",
    "          [2,4]],\n",
    "         [[3,5],\n",
    "          [8,2]]], dtype=np.float64)\n",
    "    mpl = MaxPoolingLayer(4,4,2,2,2,2)\n",
    "    return a, b, mpl\n",
    "\n",
    "\n",
    "def test_pool():\n",
    "    a, b, mpl = init_pool_test()\n",
    "    mpl.forward(a)\n",
    "    print('input array:\\n%s\\noutput array:\\n%s' % (a,mpl.output_array))\n",
    "\n",
    "\n",
    "def test_pool_bp():\n",
    "    a, b, mpl = init_pool_test()\n",
    "    mpl.backward(a, b)\n",
    "    print('input array:\\n%s\\nsensitivity array:\\n%s\\ndelta array:\\n%s' % (a, b, mpl.delta_array))                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c76c44d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ConvLayer' has no attribute 'calculate_output_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     test()\n\u001b[1;32m      3\u001b[0m     test_bp()\n\u001b[1;32m      4\u001b[0m     gradient_check()\n",
      "Cell \u001b[0;32mIn[5], line 302\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m():\n\u001b[0;32m--> 302\u001b[0m     a,b,cl\u001b[38;5;241m=\u001b[39minit_test()\n\u001b[1;32m    303\u001b[0m     cl\u001b[38;5;241m.\u001b[39mforward(a)\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cl\u001b[38;5;241m.\u001b[39moutput_array)\n",
      "Cell \u001b[0;32mIn[5], line 277\u001b[0m, in \u001b[0;36minit_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m    254\u001b[0m a\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray( \n\u001b[1;32m    255\u001b[0m     [[[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m    256\u001b[0m       [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m       [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m    269\u001b[0m       [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]]])\n\u001b[1;32m    270\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    271\u001b[0m     [[[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    272\u001b[0m       [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m       [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    276\u001b[0m       [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m]]])\n\u001b[0;32m--> 277\u001b[0m cl \u001b[38;5;241m=\u001b[39m ConvLayer(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,IdentityActivator(),\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m    278\u001b[0m cl\u001b[38;5;241m.\u001b[39mfilters[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    279\u001b[0m     [[[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    280\u001b[0m       [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m       [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    287\u001b[0m       [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    288\u001b[0m cl\u001b[38;5;241m.\u001b[39mfilters[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 121\u001b[0m, in \u001b[0;36mConvLayer.__init__\u001b[0;34m(self, input_width, input_height, channel_number, filter_width, filter_height, filter_number, zero_padding, stride, activator, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivator \u001b[38;5;241m=\u001b[39m activator\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m=\u001b[39m learning_rate\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_width \u001b[38;5;241m=\u001b[39m ConvLayer\u001b[38;5;241m.\u001b[39mcalculate_output_size(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_width, filter_width, zero_padding,stride)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_height \u001b[38;5;241m=\u001b[39m ConvLayer\u001b[38;5;241m.\u001b[39mcalculate_output_size(\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_height, filter_height, zero_padding,stride)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_number, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_height, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_width))\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ConvLayer' has no attribute 'calculate_output_size'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test()\n",
    "    test_bp()\n",
    "    gradient_check()\n",
    "    \n",
    "    test_pool()\n",
    "    test_pool_bp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cac96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
